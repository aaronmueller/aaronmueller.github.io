<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">

<title>Aaron Mueller</title>
<link rel="stylesheet" href="css/bootstrap.css">
<link rel="stylesheet" href="css/style.css">
<link rel="stylesheet" href="css/jumbotron.css">
</head>

<body>
<div class = "container">
    <div class = "header">
        <ul class = "nav nav-pills pull-right">
            <li class="Publications"><a href="publications.html">Publications</a></li>
            <li class="Resume"><a href="files/cv/CurriculumVitae.pdf" title="CV">CV</a></li>
            <li class="Prospectives"><a href="prospective.html">Prospective Students</a></li>
        </ul>
        <h3 class="text-muted"><a href="index.html">Aaron Mueller</a></h3>
    </div>

<h1>Prospective Students</h1>
<p>Thanks for your interest in joining our lab! We're recruiting PhD students and postdocs to start at BU in Fall 2025. This page is written to address questions on what our lab works on, the structure of the group, and how to apply. If you have additional questions that are not answered here, please feel free to email me with [Prospective Student] in the subject line.</p>

<section>
    <h2>Applying</h2>
    <p><b>Prospective PhD students:</b> If you are interested in joining our lab and are not currently a BU student, please apply to the <a href="https://www.bu.edu/cs/phd-program/phd/">Boston University Computer Science PhD program</a> by <b>December 15</b>. I will review all applications that mention my name.
       Please do not email me with your application materials. During admissions, if I see a good fit, I will contact you for an interview.</p>

    <p><b>Prospective postdocs:</b> Please contact me with your CV, a description of your research interests, and any outside funding you plan to apply for. Ideally, you should reach out about a year before you'd like to start.
       This may seem early, but many fellowships have very long timelines.</p>

    <p><b>Current BU PhD students who are not my advisees:</b> Email me and we can discuss!</p>

    <p><b>Current BU master's students and undergraduates:</b> Feel free to reach out, but note that I have limited availability for MS and undergraduate supervision. I will likely only
       agree to work with students who have performed well in at least one of my advanced courses, unless you already have relevant prior experience.
       </p>
</section>

<section>
    <h2>What does our lab work on?</h2>
	<div class="row">
	<div class="col-md-12">
        <p>Broadly, our lab's areas of research are natural language processing (NLP), computational linguistics, interpretability, and evaluation. Our main aim is to design
            methods, datasets, and theoretical frameworks that (i) reveal how language is learned, understood, produced, and used in natural language systems (including the mind); (ii) allow us to decipher and precisely edit/control the causal mechanisms
            underlying these capabilities in language models; and (iii) enable more efficient and robust language modeling. 
        </p>

        <p>We value linguistics and cognitive science expertise as much as machine learning expertise. Currently, our methods focus primarily on neural networks, but precedent suggests that this could quickly change. Regardless of the methods used to model it, our lab will always work with language data.
        </p>

        Below is a summary of the directions we are currently pursuing.
        <br><br>
        <ol>
            <li><b>Interpretability.</b> Language models can accomplish amazing things, but they also often fail at surprisingly simple tasks. Can we understand and predict how and why
                language models will generalize in particular ways? What causal mechanisms underlie their behaviors, and can we edit these to improve generalization?
                <ul style="font-size:10pt">
                    <li>Samuel Marks, Can Rager, Eric J. Michaud, Yonatan Belinkov, David Bau, <b>Aaron Mueller</b>. "<a href="https://arxiv.org/abs/2403.19647">Sparse Feature Circuits:  Discovering and Editing Interpretable Causal Graphs in Language Models</a>."</li>
                    <li>Matthew Finlayson*, <b>Aaron Mueller</b>*, Sebastian Gehrmann, Stuart Shieber, Tal Linzen, Yonatan Belinkov. "<a href="https://aclanthology.org/2021.acl-long.144/">Causal Analysis of Syntactic Agreement Mechanisms in Neural Language Models</a>." <em>ACL 2021</em>.</li>
                    <li>Eric Todd, Millicent Li, Arnab Sen Sharma, <b>Aaron Mueller</b>, Byron C. Wallace, David Bau. "<a href="https://arxiv.org/abs/2310.15213">Function Vectors in Large Language Models</a>." <em>ICLR 2024.</em></li>
                </ul>
            </li>
            <br>

            <li><b>Evaluation.</b> What are language models capable of? Do they process or produce language in human-like ways? What should we even be measuring? None of these questions are settled,
            but answers to them have significant implications for the kinds of work we should be pursuing.
                <ul style="font-size:10pt">
                    <li><b>Aaron Mueller</b>, Albert Webson, Jackson Petty, Tal Linzen. "<a href="https://aclanthology.org/2024.naacl-long.267/">In-context Learning Generalizes, But Not Always Robustly: The Case of Syntax</a>." <em>NAACL 2024.</em></li>
                    <li><b>Aaron Mueller</b>, Robert Frank, Tal Linzen, Luheng Wang, Sebastian Schuster. "<a href="https://aclanthology.org/2022.findings-acl.106.pdf">Coloring the Blank Slate: Pre-training Imparts a Hierarchical Inductive Bias to Sequence-to-sequence Models</a>." <em>Findings of ACL 2022</em>.</li>
                    <li><b>Aaron Mueller</b>, Garrett Nicolai, Panayiota Petrou-Zeniou, Natalia Talmina, Tal Linzen. "<a href="https://aclanthology.org/2020.acl-main.490/">Cross-Linguistic Syntactic Evaluation of Word Prediction Models</a>." <em>ACL 2020.</em></li>
                </ul>
            </li>
            <br>

            <li><b>Sample efficiency.</b> By 13 years old, a human acquires the ability to robustly understand and produce language after being exposed to less than 100 million words. Conversely,
            state-of-the-art language models are exposed to billions to trillions of words&mdash;far more than a human would hear or read in their lifetime! How can we improve language models given a
            more human-like amount of linguistic data? What kinds of signals and methods will be required for this, and can cognitive science/linguistics inspire better methods? Building efficient systems has many practical and scientific advantages, including the following:
            <ul style="list-style-type: '- ';"><li>
                <b>Learnability.</b> What kinds of data are required for a particular phenomenon to be learned? We can empirically test this if we ensure that our datasets are cognitively
                    plausible. </li> <li><b>Accessibility.</b> If less data is required to train better systems, it becomes faster and easier to iterate on language modeling methods and architectures. It also
					reduces the financial and computational opportunity cost of training a good language model, which enables more diverse research directions.</li></ul>
                <ul style="font-size:10pt">
                    <li>Alex Warstadt*, <b>Aaron Mueller</b>*, Leshem Choshen, Ethan Wilcox, Chengxu Zhuang, Juan Ciro, Rafael Mosquera, Bhargavi Paranjabe, Adina Williams, Tal Linzen, Ryan Cotterell. "<a href="https://aclanthology.org/2023.conll-babylm.1/">Findings of the BabyLM Challenge: Sample-Efficient Pretraining on Developmentally Plausible Corpora</a>." <em>CoNLL 2023.</em></li>
                    <li><b>Aaron Mueller</b>, Tal Linzen. "<a href="https://aclanthology.org/2023.acl-long.629/">How to Plant Trees in Language Models: Data and Architectural Effects on the Emergence of Syntactic Inductive Biases</a>." <em>ACL 2023.</em></li>
                </ul>
            </li>
            <br>

            <li><b>Causality.</b> When we give explanations of how or why certain systems (whether computational or human) behave in certain ways, we want our explanations to be <em>causally efficacious</em>. That is,
            we want to capture the true graph of causes and effects, rather than merely capturing commonly co-occurring events that do not actually explain the behavior. But what do we mean by cause and effect?
            How can we apply ideas from the causality literature to better analyze and understand language models? Can we automate the process of causally explaining language model behaviors?
                <ul style="font-size:10pt">
                    <li><b>Aaron Mueller.</b> "<a href="https://arxiv.org/abs/2407.04690">Missed Causes and Ambiguous Effects: Counterfactuals Pose Challenges for Interpreting Neural Networks</a>." <em>ICML 2024 Workshop on Mechanistic Interpretability (Honorable Mention &ndash; Best Paper)</em>.</li>
                    <li><b>Aaron Mueller</b>, Jannik Brinkmann, Millicent Li, Samuel Marks, Koyena Pal, Nikhil Prakash, Can Rager, Aruna Sankaranarayanan, Arnab Sen Sharma, Jiuding Sun, Eric Todd, David Bau, Yonatan Belinkov. "<a href="https://arxiv.org/abs/2408.01416">The Quest for the Right Mediator: A History, Survey, and Theoretical Grounding of Causal Interpretability</a>."</li>
                </ul>
            </li>
        </ol>
	</div>
	</div>
</section>

<section>
    <h2>Advising philosophy</h2>
    <div class="row">
        <div class="col-md-12">
            The scientific process is highly non-linear. There are many solutions to most problems, and many dead ends and challenging obstacles along the way. My role is to guide and unblock you at each step of the process, and to help you learn how to independently conduct research. I will be more hands-on earlier in your career, but
            with the ultimate goal of guiding you toward the ability to devise and pursue your own ideas.


            <h3>Goals</h3>
            <p>The purpose of a PhD program is to train new scientists, to generate new knowledge, and to help one learn the cultural and scientific norms of a research community.
                By the end of a PhD, one should have the ability to (i) devise deep but well-scoped research questions, (ii) design and be able to implement well-controlled experiments,
                (iii) lead a focused project to completion, and (iv) present one's ideas and work effectively, both in writing and orally. At a higher level, one should be able to independently design
                and pursue one's own research agenda.
            </p>

            <h3>Group structure</h3>
            <p>
                On average, I expect the group to consist of about five to eight PhD students and zero to two postdocs. This should be composed of a mixture
                of researchers with varying interests and expertise, from cognitive science and linguistics to interpretability and deep learning.
                This keeps the group small enough such that everyone knows what everyone else is doing and has regular interaction with each other. This is important, as peer mentoring can often be just as
                (if not more) effective than advisor-student mentoring! It also keeps the group large enough that many influences and priorities are always informing the direction of our work.
            </p>

            <h3>Interaction</h3>
            <p>
                I want to play an active role in my students' research projects. I plan to meet one-on-one with each of my students at least once a week. These meetings can consist of anything from project planning and technical discussion to career planning and general life
                check-ins. This is in addition to project-specific meetings. We will hold a weekly formal lab meeting once a week.
            </p>

            <h3>Work-life balance</h3>
            <p>
                Work-life balance is essential for one's intellectual and physical health. We encourage a culture of pursuing hobbies outside of Boston University.
                We also plan to do at least one social lab outing each semester.
                (Of course, the pace and amount of work necessary for successful research can vary widely
                from week to week! But on average, I believe that a healthy balance will lead to better long-term outcomes.)
            </p>
        </div>
        </div>
</section>


</div>
</body>
</html>
